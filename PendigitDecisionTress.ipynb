{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required packages \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['para1', 'para2', 'para3', 'para4', 'para5', 'para6', 'para7', 'para8', 'para9','para10','para11','para12','para13','para14','para15','para16','target']\n",
    "# load dataset\n",
    "# Function importing Dataset \n",
    "def importdata(): \n",
    "    balance_data = pd.read_csv(\"pendigitstraining.csv\", header=None, names=col_names) \n",
    "    # Printing the dataswet shape \n",
    "    print (\"Dataset Length: \", len(balance_data)) \n",
    "    print (\"Dataset Shape: \", balance_data.shape) \n",
    "      \n",
    "    # Printing the dataset obseravtions \n",
    "    print (\"Dataset: \",balance_data.head()) \n",
    "    return balance_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitdataset(balance_data):\n",
    "    # Seperating the target variable \n",
    "    feature_cols = ['para1', 'para2', 'para3', 'para4', 'para5', 'para6', 'para7', 'para8', 'para9','para10','para11','para12','para13','para14','para15','para16'] \n",
    "    X = balance_data[feature_cols]\n",
    "    Y = balance_data.target\n",
    "    \n",
    "    # Spliting the dataset into train and test \n",
    "    X_train, X_test, y_train, y_test = train_test_split(  \n",
    "    X, Y, test_size = 0.3, random_state = 100) \n",
    "      \n",
    "    return X, Y, X_train, X_test, y_train, y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_using_gini(X_train, X_test, y_train): \n",
    "  \n",
    "    # Creating the classifier object \n",
    "    clf_gini = DecisionTreeClassifier(criterion = \"gini\", \n",
    "            random_state = 100,max_depth=8, min_samples_leaf=10) \n",
    "  \n",
    "    # Performing training \n",
    "    clf_gini.fit(X_train, y_train) \n",
    "    return clf_gini "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform training with entropy. \n",
    "def tarin_using_entropy(X_train, X_test, y_train): \n",
    "  \n",
    "    # Decision tree with entropy \n",
    "    clf_entropy = DecisionTreeClassifier( \n",
    "            criterion = \"entropy\", random_state = 100, \n",
    "            max_depth = 8, min_samples_leaf = 10) \n",
    "  \n",
    "    # Performing training \n",
    "    clf_entropy.fit(X_train, y_train) \n",
    "    return clf_entropy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make test predictions \n",
    "def prediction(X_test, clf_object): \n",
    "  \n",
    "    # Predicton on test with giniIndex \n",
    "    y_pred = clf_object.predict(X_test) \n",
    "    print(\"Predicted values:\") \n",
    "    print(y_pred) \n",
    "    return y_pred \n",
    "# Function to make predictions \n",
    "def predictiont(y_train, clf_object): \n",
    "  \n",
    "    # Predicton on test with giniIndex \n",
    "    x_pred = clf_object.predict(y_train) \n",
    "    print(\"Predicted values:\") \n",
    "    print(x_pred) \n",
    "    return x_pred \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate accuracy \n",
    "def cal_accuracy(y_test, y_pred): \n",
    "      \n",
    "    print(\"Confusion Matrix: \", \n",
    "        confusion_matrix(y_test, y_pred)) \n",
    "      \n",
    "    print (\"Accuracy Test: \", \n",
    "    accuracy_score(y_test,y_pred)*100) \n",
    "       \n",
    "    print(\"Report : \", \n",
    "    classification_report(y_test, y_pred)) \n",
    "def cal_accuracyt(X_train,x_pred):\n",
    "    print (\"Accuracy Train : \", \n",
    "    accuracy_score(X_train,x_pred)*100)\n",
    "    \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Length:  7494\n",
      "Dataset Shape:  (7494, 17)\n",
      "Dataset:     para1  para2  para3  para4  para5  para6  para7  para8  para9  para10  \\\n",
      "0     47    100     27     81     57     37     26      0      0      23   \n",
      "1      0     89     27    100     42     75     29     45     15      15   \n",
      "2      0     57     31     68     72     90    100    100     76      75   \n",
      "3      0    100      7     92      5     68     19     45     86      34   \n",
      "4      0     67     49     83    100    100     81     80     60      60   \n",
      "\n",
      "   para11  para12  para13  para14  para15  para16  target  \n",
      "0      56      53     100      90      40      98       8  \n",
      "1      37       0      69       2     100       6       2  \n",
      "2      50      51      28      25      16       0       1  \n",
      "3     100      45      74      23      67       0       4  \n",
      "4      40      40      33      20      47       0       1  \n",
      "Results Using Gini Index:\n",
      "Predicted values:\n",
      "[6 1 1 ... 6 8 4]\n",
      "Confusion Matrix:  [[217   0   0   0   1   0   0   0   2   2]\n",
      " [  0 194  16   6   3   0   1   3   0   4]\n",
      " [  0  18 225   3   1   1   1   4   0   0]\n",
      " [  0   0   1 180   0   0   0   8   1   0]\n",
      " [  0   3   0   0 218   0   1   0   0   5]\n",
      " [  0   2   1   7   1 201   0   1   0   3]\n",
      " [  0   0   3   2   0   1 210   1   1   2]\n",
      " [  1   2   2   1   1   1   0 251   6   1]\n",
      " [  2   0   0   0   0   3   3   5 201   1]\n",
      " [  1   2   0   7   3   7   0   0   1 192]]\n",
      "Accuracy Test:  92.88572698977323\n",
      "Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       222\n",
      "           1       0.88      0.85      0.87       227\n",
      "           2       0.91      0.89      0.90       253\n",
      "           3       0.87      0.95      0.91       190\n",
      "           4       0.96      0.96      0.96       227\n",
      "           5       0.94      0.93      0.93       216\n",
      "           6       0.97      0.95      0.96       220\n",
      "           7       0.92      0.94      0.93       266\n",
      "           8       0.95      0.93      0.94       215\n",
      "           9       0.91      0.90      0.91       213\n",
      "\n",
      "   micro avg       0.93      0.93      0.93      2249\n",
      "   macro avg       0.93      0.93      0.93      2249\n",
      "weighted avg       0.93      0.93      0.93      2249\n",
      "\n",
      "Results Using Entropy:\n",
      "Predicted values:\n",
      "[6 1 1 ... 8 8 4]\n",
      "Confusion Matrix:  [[215   1   0   0   1   0   3   0   1   1]\n",
      " [  1 205   9   6   0   0   1   1   0   4]\n",
      " [  0  12 237   1   0   1   0   1   0   1]\n",
      " [  0   0   1 180   0   0   1   3   1   4]\n",
      " [  0   3   0   0 220   0   0   0   0   4]\n",
      " [  0   0   0   2   1 202   3   0   1   7]\n",
      " [  0   0   0   0   0   1 214   0   5   0]\n",
      " [  0   5   3   2   0   0   1 250   4   1]\n",
      " [  1   0   0   0   0   3   5   5 201   0]\n",
      " [  2   1   1   2   3   8   4   0   3 189]]\n",
      "Accuracy Test:  93.95286794130725\n",
      "Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98       222\n",
      "           1       0.90      0.90      0.90       227\n",
      "           2       0.94      0.94      0.94       253\n",
      "           3       0.93      0.95      0.94       190\n",
      "           4       0.98      0.97      0.97       227\n",
      "           5       0.94      0.94      0.94       216\n",
      "           6       0.92      0.97      0.95       220\n",
      "           7       0.96      0.94      0.95       266\n",
      "           8       0.93      0.93      0.93       215\n",
      "           9       0.90      0.89      0.89       213\n",
      "\n",
      "   micro avg       0.94      0.94      0.94      2249\n",
      "   macro avg       0.94      0.94      0.94      2249\n",
      "weighted avg       0.94      0.94      0.94      2249\n",
      "\n",
      "Training Entropy:\n",
      "Predicted values:\n",
      "[9 1 3 ... 5 0 1]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'x_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-192-3cfccad89ae2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;31m# Calling main function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-192-3cfccad89ae2>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;31m# Prediction using entropy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mX_pred_entropy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredictiont\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf_entropy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0mcal_accuracyt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_pred' is not defined"
     ]
    }
   ],
   "source": [
    "# Driver code \n",
    "def main(): \n",
    "      \n",
    "    # Building Phase \n",
    "    data = importdata() \n",
    "    X, Y, X_train, X_test, y_train, y_test = splitdataset(data) \n",
    "    clf_gini = train_using_gini(X_train, X_test, y_train) \n",
    "    clf_entropy = tarin_using_entropy(X_train, X_test, y_train) \n",
    "      \n",
    "    # Operational Phase \n",
    "    print(\"Results Using Gini Index:\") \n",
    "      \n",
    "    # Prediction using gini \n",
    "    y_pred_gini = prediction(X_test, clf_gini) \n",
    "    cal_accuracy(y_test, y_pred_gini) \n",
    "      \n",
    "    print(\"Results Using Entropy:\") \n",
    "    # Prediction using entropy \n",
    "    y_pred_entropy = prediction(X_test, clf_entropy) \n",
    "    cal_accuracy(y_test, y_pred_entropy) \n",
    "    \n",
    "    \n",
    "    print(\"Training Entropy:\") \n",
    "    # Prediction using entropy \n",
    "    X_pred_entropy = predictiont (X_train, clf_entropy) \n",
    "    cal_accuracyt(X_train,x_pred)\n",
    "        \n",
    "\n",
    "      \n",
    "      \n",
    "# Calling main function \n",
    "if __name__==\"__main__\": \n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
